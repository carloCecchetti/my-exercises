{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "driven-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "sized-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"example.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "legislative-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"img\", img)\n",
    "cv.waitKey() \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "tropical-astrology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176 175 177]\n"
     ]
    }
   ],
   "source": [
    "print(img[1151,686]) #print pixel's color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "greatest-oriental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    }
   ],
   "source": [
    "print(img[1151,686, 0]) #sicne it's BGR, it prints the Blue value of pixel at 1141,686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "native-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "img[100,100] = (0,0,255) #changing red value at pixel 100,100\n",
    "print(img[100,100,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "mexican-dallas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 1993, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "assumed-variable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7515603\n"
     ]
    }
   ],
   "source": [
    "print(img.size) #1257*1993*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "remarkable-dover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7515603"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "leading-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"pencils.jpg\")\n",
    "\n",
    "x1,y1 = 100,960\n",
    "x2,y2 = 200,960\n",
    "\n",
    "piece = img[x1:y1, x2:y2]\n",
    "img[x1:y1, x2+500:y2+500] = piece\n",
    "\n",
    "cv.imshow(\"img\", img)\n",
    "cv.waitKey() \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "continent-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Addition\n",
    "img1 = cv.imread(\"Future1280x720.jpg\")\n",
    "img2 = cv.imread(\"Background1280x720.jpg\")\n",
    "\n",
    "img3 = cv.add(img1, img2)\n",
    "img4 = cv.addWeighted(img1, 0.6, img2, 0.4,0)\n",
    "\n",
    "cv.imshow(\"Image addition\", img3)\n",
    "cv.imshow(\"Image addition wighted\", img4)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "qualified-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blending images\n",
    "img1 = cv.imread(\"Future1280x720.jpg\")\n",
    "img2 = cv.imread(\"Background1280x720.jpg\")\n",
    "\n",
    "rows,columns,channels = img1.shape\n",
    "roi = img2[0:rows, 0:columns]\n",
    "\n",
    "img1gray = cv.cvtColor(img1,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow(\"img1gray\", img1gray)\n",
    "\n",
    "ret, img1mask = cv.threshold(img1gray, 80,255, cv.THRESH_BINARY)\n",
    "cv.imshow(\"img1mask\", img1mask)\n",
    "\n",
    "img1invert = cv.bitwise_not(img1mask)\n",
    "cv.imshow(\"img1invert\", img1invert)\n",
    "\n",
    "img2_bg_invert = cv.bitwise_and(roi,roi,mask = img1invert)\n",
    "cv.imshow(\"img2_bg_invert\", img2_bg_invert)\n",
    "\n",
    "img2_bg_mask = cv.bitwise_and(roi,roi,mask = img1mask)\n",
    "cv.imshow(\"img2_bg_mask\", img2_bg_mask)\n",
    "\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fundamental-enclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COLOR_BAYER_BG2BGR', 'COLOR_BAYER_BG2BGRA', 'COLOR_BAYER_BG2BGR_EA', 'COLOR_BAYER_BG2BGR_VNG', 'COLOR_BAYER_BG2GRAY', 'COLOR_BAYER_BG2RGB', 'COLOR_BAYER_BG2RGBA', 'COLOR_BAYER_BG2RGB_EA', 'COLOR_BAYER_BG2RGB_VNG', 'COLOR_BAYER_GB2BGR', 'COLOR_BAYER_GB2BGRA', 'COLOR_BAYER_GB2BGR_EA', 'COLOR_BAYER_GB2BGR_VNG', 'COLOR_BAYER_GB2GRAY', 'COLOR_BAYER_GB2RGB', 'COLOR_BAYER_GB2RGBA', 'COLOR_BAYER_GB2RGB_EA', 'COLOR_BAYER_GB2RGB_VNG', 'COLOR_BAYER_GR2BGR', 'COLOR_BAYER_GR2BGRA', 'COLOR_BAYER_GR2BGR_EA', 'COLOR_BAYER_GR2BGR_VNG', 'COLOR_BAYER_GR2GRAY', 'COLOR_BAYER_GR2RGB', 'COLOR_BAYER_GR2RGBA', 'COLOR_BAYER_GR2RGB_EA', 'COLOR_BAYER_GR2RGB_VNG', 'COLOR_BAYER_RG2BGR', 'COLOR_BAYER_RG2BGRA', 'COLOR_BAYER_RG2BGR_EA', 'COLOR_BAYER_RG2BGR_VNG', 'COLOR_BAYER_RG2GRAY', 'COLOR_BAYER_RG2RGB', 'COLOR_BAYER_RG2RGBA', 'COLOR_BAYER_RG2RGB_EA', 'COLOR_BAYER_RG2RGB_VNG', 'COLOR_BGR2BGR555', 'COLOR_BGR2BGR565', 'COLOR_BGR2BGRA', 'COLOR_BGR2GRAY', 'COLOR_BGR2HLS', 'COLOR_BGR2HLS_FULL', 'COLOR_BGR2HSV', 'COLOR_BGR2HSV_FULL', 'COLOR_BGR2LAB', 'COLOR_BGR2LUV', 'COLOR_BGR2Lab', 'COLOR_BGR2Luv', 'COLOR_BGR2RGB', 'COLOR_BGR2RGBA', 'COLOR_BGR2XYZ', 'COLOR_BGR2YCR_CB', 'COLOR_BGR2YCrCb', 'COLOR_BGR2YUV', 'COLOR_BGR2YUV_I420', 'COLOR_BGR2YUV_IYUV', 'COLOR_BGR2YUV_YV12', 'COLOR_BGR5552BGR', 'COLOR_BGR5552BGRA', 'COLOR_BGR5552GRAY', 'COLOR_BGR5552RGB', 'COLOR_BGR5552RGBA', 'COLOR_BGR5652BGR', 'COLOR_BGR5652BGRA', 'COLOR_BGR5652GRAY', 'COLOR_BGR5652RGB', 'COLOR_BGR5652RGBA', 'COLOR_BGRA2BGR', 'COLOR_BGRA2BGR555', 'COLOR_BGRA2BGR565', 'COLOR_BGRA2GRAY', 'COLOR_BGRA2RGB', 'COLOR_BGRA2RGBA', 'COLOR_BGRA2YUV_I420', 'COLOR_BGRA2YUV_IYUV', 'COLOR_BGRA2YUV_YV12', 'COLOR_BayerBG2BGR', 'COLOR_BayerBG2BGRA', 'COLOR_BayerBG2BGR_EA', 'COLOR_BayerBG2BGR_VNG', 'COLOR_BayerBG2GRAY', 'COLOR_BayerBG2RGB', 'COLOR_BayerBG2RGBA', 'COLOR_BayerBG2RGB_EA', 'COLOR_BayerBG2RGB_VNG', 'COLOR_BayerGB2BGR', 'COLOR_BayerGB2BGRA', 'COLOR_BayerGB2BGR_EA', 'COLOR_BayerGB2BGR_VNG', 'COLOR_BayerGB2GRAY', 'COLOR_BayerGB2RGB', 'COLOR_BayerGB2RGBA', 'COLOR_BayerGB2RGB_EA', 'COLOR_BayerGB2RGB_VNG', 'COLOR_BayerGR2BGR', 'COLOR_BayerGR2BGRA', 'COLOR_BayerGR2BGR_EA', 'COLOR_BayerGR2BGR_VNG', 'COLOR_BayerGR2GRAY', 'COLOR_BayerGR2RGB', 'COLOR_BayerGR2RGBA', 'COLOR_BayerGR2RGB_EA', 'COLOR_BayerGR2RGB_VNG', 'COLOR_BayerRG2BGR', 'COLOR_BayerRG2BGRA', 'COLOR_BayerRG2BGR_EA', 'COLOR_BayerRG2BGR_VNG', 'COLOR_BayerRG2GRAY', 'COLOR_BayerRG2RGB', 'COLOR_BayerRG2RGBA', 'COLOR_BayerRG2RGB_EA', 'COLOR_BayerRG2RGB_VNG', 'COLOR_COLORCVT_MAX', 'COLOR_GRAY2BGR', 'COLOR_GRAY2BGR555', 'COLOR_GRAY2BGR565', 'COLOR_GRAY2BGRA', 'COLOR_GRAY2RGB', 'COLOR_GRAY2RGBA', 'COLOR_HLS2BGR', 'COLOR_HLS2BGR_FULL', 'COLOR_HLS2RGB', 'COLOR_HLS2RGB_FULL', 'COLOR_HSV2BGR', 'COLOR_HSV2BGR_FULL', 'COLOR_HSV2RGB', 'COLOR_HSV2RGB_FULL', 'COLOR_LAB2BGR', 'COLOR_LAB2LBGR', 'COLOR_LAB2LRGB', 'COLOR_LAB2RGB', 'COLOR_LBGR2LAB', 'COLOR_LBGR2LUV', 'COLOR_LBGR2Lab', 'COLOR_LBGR2Luv', 'COLOR_LRGB2LAB', 'COLOR_LRGB2LUV', 'COLOR_LRGB2Lab', 'COLOR_LRGB2Luv', 'COLOR_LUV2BGR', 'COLOR_LUV2LBGR', 'COLOR_LUV2LRGB', 'COLOR_LUV2RGB', 'COLOR_Lab2BGR', 'COLOR_Lab2LBGR', 'COLOR_Lab2LRGB', 'COLOR_Lab2RGB', 'COLOR_Luv2BGR', 'COLOR_Luv2LBGR', 'COLOR_Luv2LRGB', 'COLOR_Luv2RGB', 'COLOR_M_RGBA2RGBA', 'COLOR_RGB2BGR', 'COLOR_RGB2BGR555', 'COLOR_RGB2BGR565', 'COLOR_RGB2BGRA', 'COLOR_RGB2GRAY', 'COLOR_RGB2HLS', 'COLOR_RGB2HLS_FULL', 'COLOR_RGB2HSV', 'COLOR_RGB2HSV_FULL', 'COLOR_RGB2LAB', 'COLOR_RGB2LUV', 'COLOR_RGB2Lab', 'COLOR_RGB2Luv', 'COLOR_RGB2RGBA', 'COLOR_RGB2XYZ', 'COLOR_RGB2YCR_CB', 'COLOR_RGB2YCrCb', 'COLOR_RGB2YUV', 'COLOR_RGB2YUV_I420', 'COLOR_RGB2YUV_IYUV', 'COLOR_RGB2YUV_YV12', 'COLOR_RGBA2BGR', 'COLOR_RGBA2BGR555', 'COLOR_RGBA2BGR565', 'COLOR_RGBA2BGRA', 'COLOR_RGBA2GRAY', 'COLOR_RGBA2M_RGBA', 'COLOR_RGBA2RGB', 'COLOR_RGBA2YUV_I420', 'COLOR_RGBA2YUV_IYUV', 'COLOR_RGBA2YUV_YV12', 'COLOR_RGBA2mRGBA', 'COLOR_XYZ2BGR', 'COLOR_XYZ2RGB', 'COLOR_YCR_CB2BGR', 'COLOR_YCR_CB2RGB', 'COLOR_YCrCb2BGR', 'COLOR_YCrCb2RGB', 'COLOR_YUV2BGR', 'COLOR_YUV2BGRA_I420', 'COLOR_YUV2BGRA_IYUV', 'COLOR_YUV2BGRA_NV12', 'COLOR_YUV2BGRA_NV21', 'COLOR_YUV2BGRA_UYNV', 'COLOR_YUV2BGRA_UYVY', 'COLOR_YUV2BGRA_Y422', 'COLOR_YUV2BGRA_YUNV', 'COLOR_YUV2BGRA_YUY2', 'COLOR_YUV2BGRA_YUYV', 'COLOR_YUV2BGRA_YV12', 'COLOR_YUV2BGRA_YVYU', 'COLOR_YUV2BGR_I420', 'COLOR_YUV2BGR_IYUV', 'COLOR_YUV2BGR_NV12', 'COLOR_YUV2BGR_NV21', 'COLOR_YUV2BGR_UYNV', 'COLOR_YUV2BGR_UYVY', 'COLOR_YUV2BGR_Y422', 'COLOR_YUV2BGR_YUNV', 'COLOR_YUV2BGR_YUY2', 'COLOR_YUV2BGR_YUYV', 'COLOR_YUV2BGR_YV12', 'COLOR_YUV2BGR_YVYU', 'COLOR_YUV2GRAY_420', 'COLOR_YUV2GRAY_I420', 'COLOR_YUV2GRAY_IYUV', 'COLOR_YUV2GRAY_NV12', 'COLOR_YUV2GRAY_NV21', 'COLOR_YUV2GRAY_UYNV', 'COLOR_YUV2GRAY_UYVY', 'COLOR_YUV2GRAY_Y422', 'COLOR_YUV2GRAY_YUNV', 'COLOR_YUV2GRAY_YUY2', 'COLOR_YUV2GRAY_YUYV', 'COLOR_YUV2GRAY_YV12', 'COLOR_YUV2GRAY_YVYU', 'COLOR_YUV2RGB', 'COLOR_YUV2RGBA_I420', 'COLOR_YUV2RGBA_IYUV', 'COLOR_YUV2RGBA_NV12', 'COLOR_YUV2RGBA_NV21', 'COLOR_YUV2RGBA_UYNV', 'COLOR_YUV2RGBA_UYVY', 'COLOR_YUV2RGBA_Y422', 'COLOR_YUV2RGBA_YUNV', 'COLOR_YUV2RGBA_YUY2', 'COLOR_YUV2RGBA_YUYV', 'COLOR_YUV2RGBA_YV12', 'COLOR_YUV2RGBA_YVYU', 'COLOR_YUV2RGB_I420', 'COLOR_YUV2RGB_IYUV', 'COLOR_YUV2RGB_NV12', 'COLOR_YUV2RGB_NV21', 'COLOR_YUV2RGB_UYNV', 'COLOR_YUV2RGB_UYVY', 'COLOR_YUV2RGB_Y422', 'COLOR_YUV2RGB_YUNV', 'COLOR_YUV2RGB_YUY2', 'COLOR_YUV2RGB_YUYV', 'COLOR_YUV2RGB_YV12', 'COLOR_YUV2RGB_YVYU', 'COLOR_YUV420P2BGR', 'COLOR_YUV420P2BGRA', 'COLOR_YUV420P2GRAY', 'COLOR_YUV420P2RGB', 'COLOR_YUV420P2RGBA', 'COLOR_YUV420SP2BGR', 'COLOR_YUV420SP2BGRA', 'COLOR_YUV420SP2GRAY', 'COLOR_YUV420SP2RGB', 'COLOR_YUV420SP2RGBA', 'COLOR_YUV420p2BGR', 'COLOR_YUV420p2BGRA', 'COLOR_YUV420p2GRAY', 'COLOR_YUV420p2RGB', 'COLOR_YUV420p2RGBA', 'COLOR_YUV420sp2BGR', 'COLOR_YUV420sp2BGRA', 'COLOR_YUV420sp2GRAY', 'COLOR_YUV420sp2RGB', 'COLOR_YUV420sp2RGBA', 'COLOR_mRGBA2RGBA']\n"
     ]
    }
   ],
   "source": [
    "#Colorspaces\n",
    "import cv2 as cv\n",
    "flags = [i for i in dir(cv) if i.startswith('COLOR_')]\n",
    "print(flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "antique-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "while True:\n",
    "    _,bgr_frame = cap.read()\n",
    "    \n",
    "    hsv_frame = cv.cvtColor(bgr_frame, cv.COLOR_BGR2HSV)\n",
    "    \n",
    "    lowerb = np.array([0,0,0]) \n",
    "    upperb = np.array([100,184,240]) #near to my skin color (it depends a lot from light condition)\n",
    "    \n",
    "    mask = cv.inRange(hsv_frame, lowerb, upperb, cv.THRESH_BINARY)\n",
    "    #mask = cv.inRange(bgr_frame, lowerb, upperb, cv.THRESH_BINARY) \n",
    "    \n",
    "    #res = cv.bitwise_and(bgr_frame,bgr_frame, mask = mask)\n",
    "    res = cv.bitwise_not(hsv_frame,hsv_frame, mask = mask)\n",
    "    \n",
    "    res2bgr = cv.cvtColor(res, cv.COLOR_HSV2BGR)\n",
    "    \n",
    "    cv.imshow(\"bgr_frame\",bgr_frame)\n",
    "    cv.imshow(\"hsv_frame\",hsv_frame)\n",
    "    cv.imshow(\"res\",res)\n",
    "    cv.imshow(\"res2bgr\",res2bgr)\n",
    "    if cv.waitKey(1) == 113:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-equality",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "As said in the previous cell, global thresholding is not good when working with different light condition.  \n",
    "To avoid this problems, we can suse Adaptive Thresholding.  \n",
    "In few words, adaptive thresholding allows us to have different thresholding values for different areas.  \n",
    "It has 3 input paramethers:  \n",
    "1. Adaptive method:  \n",
    "   - ADAPTIVE_THRESH_MEAN_C: The threshold value is the mean of neighbourhood area  \n",
    "   - \"\"_\"\"_GAUSSIAN_C: threshold value is the wheighted sum of neighbourhood values  \n",
    "            \n",
    "            \n",
    "2. Block Size: How big are the neighbourhood areas   \n",
    "   \n",
    "3. Constant subtracted from the mean calculated  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "educational-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture(0) #capture\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read() #reading frames\n",
    "    \n",
    "    grayFrame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) #from bgr to black and gray shadows\n",
    "    blurredFrame = cv.GaussianBlur(grayFrame, (5,5), 7) #blurring to remove image noise\n",
    "                                        #src,      maxValue  #adaptive threshold method,     threshold type, block dim to calculate means, C\n",
    "    thresholdFrame = cv.adaptiveThreshold(blurredFrame, 200, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 19, 3)\n",
    "    ret, thresholdFrame = cv.threshold(thresholdFrame, 25, 255, cv.THRESH_BINARY) #used to clarify the result\n",
    "    \n",
    "    cv.imshow(\"AdaptiveThreshold\", thresholdFrame)\n",
    "    if cv.waitKey(1) == 113:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
